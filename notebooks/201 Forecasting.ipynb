{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f82de313-3ec3-460d-bc18-dd33074cfe06",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Tangent Databricks Tutorial - Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f9d77bed-e49b-4bc4-81c9-8903b037742b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "In this tutorial, you will learn to build a forecasting model with Tangent, generate predictions using this model and use additional capabilities.  \n",
    "The Forecasting module exists to have controle over all the steps in the model building & prediction process. The main steps are:\n",
    "1. building a model using historical training data.\n",
    "2. making an inference using this model.\n",
    "\n",
    "To show the capabilities of the Forecasting module, we will use an example dataset from a retail sales forecasting use case.  \n",
    "The goal is to forecast sales of a specific product 7 days ahead using historical sales data and other explanatory variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6b5455f5-0d71-40ca-9dcd-d044c5687f9b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9afeb5bf-420a-4612-b1d6-0583987fb9f6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "First, import the tangent_works package and other supporting libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5def642-b0d9-43ea-9002-03a2a663c61e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import tangent_works as tw\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activate the package with the access token to the Tangent API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "credentials = json.load(open('../credentials.json'))\n",
    "os.environ[\"TANGENT_LICENSE\"] = (credentials['token'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ddaf0f8-e45e-4c4b-b399-74b32d02f115",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "To visualize the results of this exercise, the following visualization functions can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1842ce06-b85d-4715-b9e4-a2cd96cc694e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------------- Supporting Libraries --------------------------------\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.subplots as splt\n",
    "\n",
    "class visualization:\n",
    "    def predictor_importance(df):\n",
    "        v_data = df[df['importance']>0]\n",
    "        x_axis = 'name'\n",
    "        y_axis = 'rel_importance'\n",
    "        fig1 = go.Figure(go.Bar(x=v_data[x_axis], y=v_data[y_axis],text=round(v_data[y_axis],2),textposition='auto'))\n",
    "        fig1.update_layout(height=500,width=1000,title_text='Predictor Importances',xaxis_title=x_axis,yaxis_title=y_axis)\n",
    "        print('Predictors not used:'+str(list(df[~(df['importance']>0)]['name'])))\n",
    "        fig1.show()\n",
    "\n",
    "    def feature_importance(df):\n",
    "        fig = px.treemap(df, path=[px.Constant(\"all\"), 'model', 'feature'], values='importance',hover_data='beta',color='feature')\n",
    "        fig.update_traces(root_color=\"lightgrey\")\n",
    "        fig.update_layout(height=600, width=1000, title_text=\"Features\",margin = dict(t=50, l=25, r=25, b=25))\n",
    "        fig.show()\n",
    "\n",
    "    def predictions(df):\n",
    "        fig = splt.make_subplots(rows=1, cols=1, shared_xaxes=True, vertical_spacing=0.02)\n",
    "        color_map = {'training':'green','testing':'red','production':'goldenrod'}\n",
    "        fig.add_trace(go.Scatter(x=df['timestamp'], y=df['target'], name='target',line=dict(color='black')), row=1, col=1)\n",
    "        for forecasting_type in df['type'].unique():\n",
    "            v_data = df[df['type']==forecasting_type].copy()\n",
    "            fig.add_trace(go.Scatter(x=v_data['timestamp'], y=v_data['forecast'], name=forecasting_type,line=dict(color=color_map[forecasting_type])), row=1, col=1)\n",
    "        fig.update_layout(height=500, width=1000, title_text=\"Results\")\n",
    "        fig.show()\n",
    "\n",
    "    def data(df,timestamp,target,predictors):\n",
    "        fig = splt.make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.02)\n",
    "        fig.add_trace(go.Scatter(x=df[timestamp], y=df[target], name=target,connectgaps=True), row=1, col=1)\n",
    "        for idx, p in enumerate(predictors): fig.add_trace(go.Scatter(x=df[timestamp], y=df[p], name=p,connectgaps=True), row=2, col=1)\n",
    "        fig.update_layout(height=600, width=1100, title_text=\"Data visualization\")\n",
    "        fig.show()\n",
    "\n",
    "    def rca(time_series,timestamp_column,target_column,df,rca_tables_df,rca_timestamp,window=48):\n",
    "        rca_tables_df['timestamp'] = pd.to_datetime(rca_tables_df['timestamp'])\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        try:\n",
    "            df = df.rename(columns={'normal_behavior':'forecast'})\n",
    "        except:\n",
    "            pass\n",
    "        rca_index = df[df['timestamp']==rca_timestamp].index[0]\n",
    "        v_data = time_series.iloc[rca_index-window:rca_index+window]\n",
    "        v_results = df[(df['timestamp']>=v_data[timestamp_column].min())&(df['timestamp']<=v_data[timestamp_column].max())]\n",
    "        v_rca = rca_tables_df[(rca_tables_df['type']=='yhat')&(rca_tables_df['timestamp']==rca_timestamp)]\n",
    "        trace_list_1,trace_list_2,trace_list_3 = [],[],[]\n",
    "        for i in range(len(v_rca)):\n",
    "            yhat_df = pd.concat([v_results[v_results['timestamp']!=rca_timestamp][['timestamp','forecast']],pd.DataFrame(v_rca.iloc[i][['timestamp','value']]).transpose().rename(columns={'value':'forecast'})]).sort_values(by='timestamp')\n",
    "            visibility = True if i==0 else False\n",
    "            trace_list_1.append(go.Scatter(x=list(v_data[timestamp_column]),y=list(v_data[target_column]), visible=visibility, line={'color': 'black'},name='target'))\n",
    "            trace_list_2.append(go.Scatter(x=list(v_results['timestamp']),y=list(v_results['forecast']), visible=visibility, line={'color': 'red'},name='forecast'))\n",
    "            trace_list_3.append(go.Scatter(x=list(yhat_df['timestamp']),y=list(yhat_df['forecast']), visible=visibility, line={'color': 'orange'},name=v_rca.iloc[i]['term']))\n",
    "\n",
    "        fig = go.Figure(data=trace_list_1+trace_list_2+trace_list_3)\n",
    "        fig.add_trace(go.Scatter(x=v_data[timestamp_column], y=v_data[target_column], name=target_column, line=dict(color='black')))\n",
    "        steps = []\n",
    "        num_steps = len(trace_list_1)\n",
    "        for i in range(num_steps):\n",
    "            step = dict(method = 'restyle',args = ['visible', [False] * len(fig.data)])\n",
    "            step['args'][1][i] = True\n",
    "            step['args'][1][i+num_steps] = True\n",
    "            step['args'][1][i+num_steps*2] = True\n",
    "            steps.append(step)\n",
    "        sliders = [dict(steps = steps,y= -0.05)]\n",
    "        fig.layout.sliders = sliders \n",
    "        fig.add_vline(x=rca_timestamp, line_dash=\"dash\", line_color=\"green\")\n",
    "        fig.update_layout(height=600,width=1200,title_text='Model Timestamp Analysis',legend=dict(y=-0.4,x=0.0,orientation='h'))\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27439ac6-0c7a-4192-8387-40ea63119a18",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 1. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "63a7c0b9-a2ab-4a9c-840a-03d6d5474c92",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The dataset that will be used in this notebook is called inventory_management.  \n",
    "It contains historical daily sales data and customer presence information as well as public holiday, calendar information and promotions.  \n",
    "In the cell below, this dataset is preprocessed and made ready for use with Tangent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae789c05-11d7-48ae-92aa-5cfdbfc10159",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "file_path = '../data/inventory_management.csv'\n",
    "tangent_dataframe = pd.read_csv(file_path).head(949)\n",
    "group_keys = []\n",
    "timestamp_column = \"Date\"\n",
    "target_column = \"Sales\"\n",
    "predictors = [s for s in list(tangent_dataframe.columns) if s not in group_keys + [timestamp_column, target_column]]\n",
    "tangent_dataframe = tangent_dataframe[group_keys + [timestamp_column, target_column] + predictors].sort_values(by=group_keys + [timestamp_column]).reset_index(drop=True)\n",
    "tangent_dataframe[timestamp_column] = pd.to_datetime(pd.to_datetime(tangent_dataframe[timestamp_column]).dt.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "tangent_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0432a84-0a8f-4962-82d8-a0b60360a261",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "In time series analysis, when exploring a dataset, it is best practice to visualize the data and learn which patterns might exists in the data that we want Tangent to identify automatically.  \n",
    "In this graph, the target column \"Sales\" is visualized above and the additional explanatory variables or predictors are visualized below.  \n",
    "Notice that for some predictors, values are available ahead of the last target timestamp throughout the forecast horizon. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d315547e-6e9d-48b2-ad17-54782934e684",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "visualization.data(df=tangent_dataframe,timestamp=timestamp_column,target=target_column,predictors=predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e352427c-72ad-491a-aac8-6f3ed77da92f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 2. Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ce97d80-54b2-4e64-868e-f16e70eb804d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The first step in the forecasting process using the Forecasting module is model building. To describe to Tangent, how it should build a model using this dataset, we can use the configuration below.  \n",
    "Many settings can be applied, however Tangent is designed to automate as much as possible. When a parameter is not set, Tangent will assume default settings.  \n",
    "In that case, Tangent will decided how to apply certain settings for you. You can find the final result in the forecasting object after model building.  \n",
    "\n",
    "In this example, default settings will be used. The only configuration will be the forecasting horizon, which is here set from sample+1 until sample+7.  \n",
    "Tangent will automatically recognize the most likely sampling rate, in this case daily, and build a time series forecasting model to predict values for the next 7 days. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "832b2cde-c08c-47da-92e1-4e6ddad8ad70",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "build_model_configuration = {\n",
    "    # 'target_column': 'string',\n",
    "    # 'categorical_columns': [\n",
    "    #     'string'\n",
    "    # ],\n",
    "    # 'holiday_column': 'string',\n",
    "    'prediction_from': {\n",
    "        'base_unit': 'sample',\n",
    "        'value': 1\n",
    "    },\n",
    "    'prediction_to': {\n",
    "        'base_unit': 'sample',\n",
    "        'value': 7\n",
    "    },\n",
    "    # 'target_offsets': 'combined',\n",
    "    # 'predictor_offsets': 'common',\n",
    "    # 'allow_offsets': True,\n",
    "    # 'max_offsets_depth': 0,\n",
    "    # 'normalization': True,\n",
    "    # 'max_feature_count': 20,\n",
    "    # 'transformations': [\n",
    "    #     'exponential_moving_average',\n",
    "    #     'rest_of_week',\n",
    "    #     'periodic',\n",
    "    #     'intercept',\n",
    "    #     'piecewise_linear',\n",
    "    #     'time_offsets',\n",
    "    #     'polynomial',\n",
    "    #     'identity',\n",
    "    #     'simple_moving_average',\n",
    "    #     'month',\n",
    "    #     'trend',\n",
    "    #     'day_of_week',\n",
    "    #     'fourier',\n",
    "    #     'public_holidays',\n",
    "    #     'one_hot_encoding'\n",
    "    # ],\n",
    "    # 'daily_cycle': True,\n",
    "    # 'confidence_level': 90,\n",
    "    # 'data_alignment': [\n",
    "    #     {\n",
    "    #         'column_name': 'string',\n",
    "    #         'timestamp': 'yyyy-mm-dd hh:mm:ssZ'\n",
    "    #     }\n",
    "    # ],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ca1a98b4-38f7-4402-a6dd-a4e2e3add257",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "For the inference step, a configuration also needs to be specified. Here we will describe the same setup as in model building: predict from sample+1 to sample+7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "beeb8c16-c465-459d-84eb-0524f110e62c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "predict_configuration = {\n",
    "    'prediction_from': {\n",
    "        'base_unit': 'sample',\n",
    "        'value': 1\n",
    "        },\n",
    "    'prediction_to': {\n",
    "        'base_unit': 'sample',\n",
    "        'value': 7\n",
    "    }, \n",
    "    # 'prediction_boundaries': {\n",
    "    #     'type': 'explicit',\n",
    "    #     'max_value': 100,\n",
    "    #     'min_value': 0\n",
    "    # },\n",
    "    # 'data_alignment': [\n",
    "    #     {\n",
    "    #         'column_name': 'string',\n",
    "    #         'timestamp': 'yyyy-mm-dd hh:mm:ssZ'\n",
    "    #     }\n",
    "    # ],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "104ef510-0ae1-4a6d-89b1-05fe304fc45c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 3. Tangent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "682c95fa-849d-4c69-8a08-be0fe338c14c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "In this section, the following steps take place:\n",
    "1. Create and validate a Tangent time series object\n",
    "2. Create a Forecasting object by combining a time series and model building configuration.\n",
    "3. Send a model building request by applying the \"build_model\" function.\n",
    "4. Send a forecast request by applying the \"forecast\" function and using the predict configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7ce18db-8fbf-43d9-93fc-43f8f9ca4f1f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "time_series = tw.TimeSeries(data= tangent_dataframe, timestamp_column=timestamp_column)\n",
    "time_series.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1714f6da-5aab-45da-a2f5-9b68051ac6bd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tangent_forecast = tw.Forecasting(time_series=time_series,configuration = build_model_configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15d731d1-4d99-431a-9949-c86d8ae4584e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tangent_forecast.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac6ba2ab-2647-4a34-8c56-3618aceeabc2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tangent_predictions = tangent_forecast.forecast(\n",
    "    configuration=predict_configuration\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e4a88127-a420-487b-8719-fb7766dae3d8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's extract the model from the Forecasting object to get insights in the model building process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe4f1ac1-29e0-41f7-aac9-1579a6cdecc2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tangent_forecast_model = tangent_forecast.model.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "215bce7c-661e-47a8-a4c8-e0eb4a5a5f5f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 4. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "999213c0-47c4-4c5a-99fd-275032305965",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The model and the Forecasting object can now post processed into tables that can either be stored, analyzed or visualized by the user.  \n",
    "Below, the properties and features of the model are extracted. In addition, information about the type of forecasts is added to table with predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5c177c3-fd2c-42f5-a361-e251965cf9bb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "properties_df = tw.PostProcessing().properties(model=tangent_forecast_model)\n",
    "features_df = tw.PostProcessing().features(model=tangent_forecast_model)\n",
    "result_table_df = tw.PostProcessing().result_table(forecasting=tangent_forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "edea9341-115e-4f72-bafa-91fcf1e88f40",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 5. Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e7cb8e9-d629-40bf-aec1-b7d5f32f4fa1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "All results can be easily visualized using the provided templates.  \n",
    "The graph below shows:\n",
    "- The __\"target\"__ or historical sales values.\n",
    "- The __\"training\"__ forecast which are the in sample results that lie on top of the training data.  \n",
    "These can be used to learn if Tangent has created a model that fits the original training data well.\n",
    "They show several 7 day ahead forecasts throughout the training period.\n",
    "- the __\"production\"__ forecast which contains the out of sample predictions and are the objective of this exercise.  \n",
    "In this example, we can recognize a 7 day ahead forecast relative from the last available target value.  \n",
    "\n",
    "When exploring the graph, we can recognize that a useful pattern seems to have been identified by Tangent which allows us to accurately forecast 7 days into the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f4951a7-6648-4f20-be98-5f39a5476b58",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "visualization.predictions(result_table_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d9e3a0c-b897-4587-beeb-33bf467d7231",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "In order to understand which patterns Tangent has identified to achieve this forecast, we can visualize several levels of insights.  \n",
    "\n",
    "Firstly, the properties, which show the relative importance of each of the columns of the dataset.  \n",
    "Here, we learn which columns contributed a lot of predictive value to the model and where a lot of useful features have been found.  \n",
    "If there are predictors from which no features were included in the model building by Tangent, then they will be listed here as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f40278d9-0ea8-442b-81d9-15a4cd08c35c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "visualization.predictor_importance(properties_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a0301a2-bc8c-4af8-ad41-fa4398136681",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Secondly, the actual features from the Tangent model can be visualized as well.  \n",
    "In this treemap graph, the relative importance of each of the features from each model in the model zoo can be quickly identified.  \n",
    "These are the predictive patterns that are hidden within the data that Tangent has automatically extracted from the data.  \n",
    "\n",
    "Tangent builds multihorizon time series models, meaning for each step in the forecasting horizon, Tangent will by default build a unique model. These models are then combined in a model zoo which is the result that the user receices.  \n",
    "With this capability, Tangent remains adaptable in modeling different patterns that can be usefull to seperate along the forecasting horizon.  \n",
    "Also, the further out in the horizon, the more uncertainty exists, and this can be easily managed by creating different models in a model zoo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c030ca9f-1976-4b01-8042-eab719e66bc8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "visualization.feature_importance(features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01d13118-4db5-481d-bc25-d41d03b24c60",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 6. Root Cause Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f739f73-de14-4ff5-8b3c-cffa1d8f6f70",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "An extended capability of Tangent is to apply Root Cause Analysis (RCA) to the predictions.  \n",
    "With RCA, we can combine the information from both the features in the model as well as the predictions and apply this to a single timestamp in the dataset.  \n",
    "\n",
    "A Tangent model is a cumulative addition of identified features that each explain a bit more of the variance in the target signal.  \n",
    "We can visualize the addition of these features to the model and learn which features contribute to either useful movements or possibly unexpected movements in the prediction.\n",
    "\n",
    "The example below first extracts from Tangent how each and every single prediction is built up. This information is processed and from there, the user can select a specific timestamp to analyze and choose a window around that timestamp for additional context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "017c8ca5-ca38-4869-8761-261bce84e330",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tangent_forecast_rca = tangent_forecast.rca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2b3c6a9-4131-4c8d-a797-a69d8f2cc4ea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rca_tables = []\n",
    "for model_index in sorted(tangent_forecast_rca.keys()):\n",
    "    rca_table = tangent_forecast_rca[model_index].melt(id_vars='timestamp')\n",
    "    rca_table['model_index'] = model_index\n",
    "    rca_tables.append(rca_table)\n",
    "rca_tables_df = pd.concat(rca_tables)\n",
    "rca_tables_df['type'] = np.where(rca_tables_df['variable'].str.contains('term '),'term',np.where(rca_tables_df['variable'].str.contains('yhat '),'yhat','other'))\n",
    "rca_tables_df['term'] = np.where(rca_tables_df['type'].isin(['term','yhat']),rca_tables_df['variable'].str.replace('term ','').str.replace('yhat ',''),np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9969151f-4696-47f2-b7a7-7b11ccc1e0cc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Move the slider from left to right to add the different features into the model to eventually come to the final predicted value.  \n",
    "The black line are the original measured values. The orange line shows the RCA values that dynamically moves as features are added.  \n",
    "The red line shows the eventual prediction that will correspond with the orange line when the slider is moved entirely to the right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4573555-f855-4424-94c0-9cb4fc63f2d4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rca_timestamp = pd.to_datetime('2014-09-15')\n",
    "window = 20\n",
    "visualization.rca(\n",
    "    time_series=tangent_dataframe,\n",
    "    timestamp_column=timestamp_column,\n",
    "    target_column=target_column,\n",
    "    df=tangent_predictions,\n",
    "    rca_tables_df=rca_tables_df,\n",
    "    rca_timestamp=rca_timestamp,\n",
    "    window=window\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "201 Forecasting",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
